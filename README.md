# ibm_data_science_specialization-capstone-project
This repo contains all the code files of a capstone project I completed as part of the IBM Data Science Specialization offered as a Professional Certificate in Coursera.  

Specialization Link: [IBM Data Science Professional Certificate](https://www.coursera.org/professional-certificates/ibm-data-science)

View my verified certificate here: [certificate link](https://coursera.org/share/bf8d24cd39fc3936addd5363913f6554)

This repo contains a total of 8 code files, each used for a specific task, which are mentioned below,

1. [Data Collection - API](00-spacex-data-collection-api.ipynb): In this notebook, I have used SpaceX API along with the requests module to collect data on rocket launches
2. [Data COllection - Scrapping](01-webscraping.ipynb): In this notebook, web scrapping has been performed on the SpaceX Wikipedia page using the Beautiful Soup library. Then, the response is processed into a data frame.
3. [Data Wrangling](02-data_wrangling.ipynb): In this notebook, a few tasks have been performed to replace null values and other methods to make the data into a usable format
4. [EDA - SQLlite](03-eda-sql-coursera_sqllite.ipynb): In this notebook, an SQL table has been created, and few queries have been performed on the same using sqllite and magic commands in jupyter notebook
5. [EDA - Visualisations](04-eda-dataviz.ipynb): In this notebook, various visualizations (scatterplots, line plots, bar charts, etc.) have been created in order to get a better understanding of the data and to gather valuable insights from it
6. [Launch Site Locations](05-launch_site_location.ipynb): In this notebook, using the Folium library, the launch sites (along with their success rates) are marked on the world map
7. [Dashboard App](06-spacex_das_app.py): In this Python file, an interactive dashboard app is created to visualize the launch data in pie charts and scatter plots. This has been done using Plotly and Dash libraries
8. [Predictive Modelling](07-Machine_Learning_Prediction.ipynb): In this final notebook, the processed data is split into training and testing data, and various standard machine learning models are built using training data. Finally, all of them are evaluated on test data. 
